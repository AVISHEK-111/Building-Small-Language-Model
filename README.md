# Building-Small-Language-Model
Built a 6-layer GPT-style language model from scratch on the TinyStories dataset. Tokenized text with tiktoken, used memory-mapped files, trained with mixed-precision and gradient accumulation, and generated coherent text, demonstrating an end-to-end language modeling pipeline.
